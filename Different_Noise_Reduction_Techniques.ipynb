{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYzjQHxibdcG"
      },
      "outputs": [],
      "source": [
        "import noisereduce as nr\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "# Load audio file\n",
        "y, sr = librosa.load(\"/content/drive/MyDrive/AI internship/Audio_files/2/05599ADA-6B7A-426A-81CE-2725BEB26D94.wav\", sr=None)\n",
        "\n",
        "# Perform noise reduction\n",
        "reduced_noise = nr.reduce_noise(y=y, sr=sr)\n",
        "\n",
        "# Save the enhanced audio to a new file\n",
        "sf.write(\"/content/drive/MyDrive/AI internship/Audio_files/Noise_Removal_Files/denoised.wav\", reduced_noise, sr)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wavelet based Algorithm\n",
        "pip install PyWavelets numpy matplotlib soundfile\n",
        "pip show PyWavelets numpy matplotlib soundfile\n",
        "import pywt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import soundfile as sf\n",
        "\n",
        "# Load the noisy audio signal\n",
        "input_audio_file = \"/content/drive/MyDrive/Category 2/B2A4D737-AFBD-44AA-B434-88E9568C000D.wav\"\n",
        "noisy_signal, sample_rate = sf.read(input_audio_file)\n",
        "\n",
        "# Define the wavelet and level of decomposition\n",
        "wavelet = 'db4'  # Choose a wavelet, e.g., 'db4'\n",
        "level = 5  # Level of decomposition (adjust as needed)\n",
        "\n",
        "# Perform wavelet decomposition\n",
        "coeffs = pywt.wavedec(noisy_signal, wavelet, level=level)\n",
        "\n",
        "# Threshold the detail coefficients (soft or hard thresholding)\n",
        "threshold = 0.01  # Adjust the threshold as needed\n",
        "coeffs_thresh = [pywt.threshold(detail, threshold, mode='soft') for detail in coeffs[1:]]\n",
        "\n",
        "# Reconstruct the denoised signal\n",
        "denoised_signal = pywt.waverec([coeffs[0]] + coeffs_thresh, wavelet)\n",
        "\n",
        "# Save the denoised audio to an output file with a .wav extension\n",
        "output_audio_file = \"/content/drive/MyDrive/combined_output.wav\"\n",
        "sf.write(output_audio_file, denoised_signal, sample_rate)\n",
        "\n",
        "# Plot and display the original and denoised signals (optional)\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.title(\"Noisy Signal\")\n",
        "plt.plot(noisy_signal)\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.title(\"Denoised Signal\")\n",
        "plt.plot(denoised_signal)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VsZhTalRb9Le"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Nomalized LMS filter\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "from scipy.signal import lfilter\n",
        "\n",
        "def normalized_lms_filter(signal, mu=0.5, N=64):\n",
        "    w = np.zeros(N)  # Initialize the filter weights\n",
        "    output = np.zeros_like(signal)  # Initialize the output signal\n",
        "\n",
        "    for i in range(N, len(signal)):\n",
        "        x = signal[i-N:i]  # Extract the input vector\n",
        "        y = np.dot(w, x)  # Compute the output of the adaptive filter\n",
        "        e = signal[i] - y  # Compute the error signal\n",
        "        norm_x = np.dot(x, x) + 1e-6  # Avoid division by zero\n",
        "        w += (mu / norm_x) * e * x  # Update the filter weights using the NLMS algorithm\n",
        "        output[i] = y  # Store the output of the adaptive filter\n",
        "\n",
        "    return output\n",
        "\n",
        "# Load the uploaded audio file\n",
        "file_path = '/path/to/your/audio/file.wav'  # Replace with the path to your audio file\n",
        "sr, audio = wavfile.read(file_path)\n",
        "audio = audio.astype(np.float32) / np.iinfo(np.int16).max  # Assuming the original data type is int16\n",
        "\n",
        "# Apply the NLMS adaptive filter\n",
        "filtered_audio = normalized_lms_filter(audio)\n",
        "\n",
        "# Save the filtered audio to a new file\n",
        "output_file_path = '/path/to/your/output/file.wav'  # Replace with the path where you want to save the output file\n",
        "wavfile.write(output_file_path, sr, (filtered_audio * np.iinfo(np.int16).max).astype(np.int16))"
      ],
      "metadata": {
        "id": "Ki-9QQnMcIHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Wiener Filter\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.signal import stft, istft\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "k2# Function to normalize audio\n",
        "def normalize_audio(input_signal, target_rms=0.1):\n",
        "    current_rms = np.sqrt(np.mean(np.square(input_signal)))\n",
        "    if current_rms == 0:\n",
        "        return input_signal\n",
        "    factor = target_rms / current_rms\n",
        "    normalized_audio = input_signal * factor\n",
        "    return normalized_audio\n",
        "\n",
        "# Function to perform noise reduction using Wiener filtering\n",
        "def wiener_filter_noise_reduction(signal, noise_segment, n_fft=2048, hop_length=512):\n",
        "    _, _, Zxx = stft(signal, nperseg=n_fft, noverlap=hop_length)\n",
        "    _, _, Zxx_noise = stft(noise_segment, nperseg=n_fft, noverlap=hop_length)\n",
        "    noise_psd = np.mean(np.abs(Zxx_noise) ** 2, axis=1)\n",
        "    signal_psd = np.abs(Zxx) ** 2\n",
        "    wiener_filter = signal_psd / (signal_psd + noise_psd[:, np.newaxis] + 1e-10)\n",
        "    Zxx_reduced = wiener_filter * Zxx\n",
        "    _, reduced_signal = istft(Zxx_reduced, noverlap=hop_length)\n",
        "    reduced_signal *= np.linalg.norm(signal) / np.linalg.norm(reduced_signal)\n",
        "    return reduced_signal\n",
        "\n",
        "# Load the audio file from Google Drive\n",
        "file_path = '/content/drive/YourPath/0A534BFB-8002-418E-B3AA-661E5EB369AC.wav' # Adjust your file path\n",
        "audio, sr = librosa.load(file_path, sr=None)\n",
        "noise_sample = audio[:int(0.5 * sr)] # You can adjust the duration for the noise sample as per your requirement\n",
        "\n",
        "# Apply Wiener filter noise reduction\n",
        "denoised_audio = wiener_filter_noise_reduction(audio, noise_sample)\n",
        "\n",
        "# Plot the waveform of the denoised audio\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.waveshow(denoised_audio, sr=sr)\n",
        "plt.title('Waveform of Audio after Wiener Filter Noise Reduction')\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.show()\n",
        "\n",
        "# Save the denoised audio to a new file\n",
        "output_file_path = '/content/drive/YourPath/denoised_audio.wav' # Adjust your output file path\n",
        "librosa.output.write_wav(output_file_path, denoised_audio, sr)"
      ],
      "metadata": {
        "id": "jGLXMP6mcRuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install speechbrain"
      ],
      "metadata": {
        "id": "tFFsKf5EckOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Short-Time Fourier Transform (STFT)\n",
        "import numpy as np\n",
        "import librosa\n",
        "from scipy.signal import stft, istft\n",
        "import soundfile as sf\n",
        "\n",
        "# Load the audio file\n",
        "file_path_advanced = '/path/to/your/audio/file.wav'  # Replace with the path to your audio file\n",
        "audio_advanced, sr_advanced = librosa.load(file_path_advanced, sr=None)\n",
        "\n",
        "# Define the frame length and hop length for the STFT\n",
        "frame_length_advanced = int(sr_advanced * 0.025)  # 25 ms frames\n",
        "hop_length_advanced = frame_length_advanced // 2  # 50% overlap\n",
        "\n",
        "# Compute the STFT of the audio signal\n",
        "f_advanced, t_advanced, Zxx_advanced = stft(audio_advanced, fs=sr_advanced, nperseg=frame_length_advanced, noverlap=hop_length_advanced)\n",
        "\n",
        "# Initialize variables to store the noise estimate and the noise mask\n",
        "noise_est_advanced = np.zeros_like(Zxx_advanced)\n",
        "noise_mask_advanced = np.ones_like(Zxx_advanced)\n",
        "\n",
        "# Define the number of frames to use for the initial noise estimate and the alpha parameter for noise estimation\n",
        "init_frames_advanced = 5  # Use the first 5 frames to initialize the noise estimate\n",
        "alpha_advanced = 0.9  # Smoothing factor for noise estimation\n",
        "\n",
        "# Initialize the noise estimate using the first few frames of the audio signal\n",
        "noise_est_advanced[:, :init_frames_advanced] = np.abs(Zxx_advanced[:, :init_frames_advanced])\n",
        "\n",
        "# Iterate over each frame and update the noise estimate and compute the noise mask\n",
        "for i in range(init_frames_advanced, Zxx_advanced.shape[1]):\n",
        "    # Update the noise estimate using a first-order recursive filter\n",
        "    noise_est_advanced[:, i] = alpha_advanced * noise_est_advanced[:, i - 1] + (1 - alpha_advanced) * np.abs(Zxx_advanced[:, i])\n",
        "\n",
        "    # Compute the noise mask based on the updated noise estimate\n",
        "    noise_mask_advanced[:, i] = 1 - (noise_est_advanced[:, i] / (np.abs(Zxx_advanced[:, i]) + 1e-10))\n",
        "\n",
        "# Apply the noise mask to the noisy STFT to obtain the clean STFT\n",
        "Zxx_clean_advanced = noise_mask_advanced * Zxx_advanced\n",
        "\n",
        "# Perform the inverse STFT to obtain the time-domain signal of the clean audio\n",
        "_, audio_clean_advanced = istft(Zxx_clean_advanced, fs=sr_advanced, noverlap=hop_length_advanced)\n",
        "\n",
        "# Normalize the amplitude of the clean audio\n",
        "audio_clean_advanced *= np.linalg.norm(audio_advanced) / np.linalg.norm(audio_clean_advanced)\n",
        "\n",
        "# Save the cleaned audio to a new file\n",
        "output_file_path_advanced = '/path/to/your/output/audio/file.wav'  # Replace with the path where you want to save the output file\n",
        "sf.write(output_file_path_advanced, audio_clean_advanced, sr_advanced)"
      ],
      "metadata": {
        "id": "azi1Xe4ecksj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Root Mean Square(RMS Level)\n",
        "import noisereduce as nr\n",
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "\n",
        "# Load the audio file\n",
        "file_path = '/content/drive/MyDrive/2/71A30F1B-9E3C-42A6-98C4-FD04A8E188EA.wav'  # Replace with the path to your audio file\n",
        "audio, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "# Amplify the noise (You can adjust the amplification factor as needed)\n",
        "amplification_factor = 1.7\n",
        "amplified_audio = audio * amplification_factor\n",
        "\n",
        "# Perform noise reduction on the amplified noise\n",
        "denoised_audio = nr.reduce_noise(sr=sr, y=amplified_audio)\n",
        "\n",
        "# Normalize the denoised audio to the same RMS level as the original audio\n",
        "rms_original = np.sqrt(np.mean(audio**2))\n",
        "rms_denoised = np.sqrt(np.mean(denoised_audio**2))\n",
        "normalized_audio = denoised_audio * (rms_original / rms_denoised)\n",
        "\n",
        "# Save the normalized denoised audio to a new file\n",
        "output_file_path = '/content/drive/MyDrive/Audio_out/file88EA.wav'  # Replace with the path where you want to save the output file\n",
        "sf.write(output_file_path, normalized_audio, sr)"
      ],
      "metadata": {
        "id": "MbAiSPPtc5No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Speech Brain\n",
        "from speechbrain.pretrained import SepformerSeparation as separator\n",
        "import torchaudio\n",
        "\n",
        "# Initialize the separator model from SpeechBrain\n",
        "model = separator.from_hparams(\n",
        "    source=\"speechbrain/sepformer-dns4-16k-enhancement\",\n",
        "    savedir='tmpdir/sepformer-dns4-16k-enhancement'\n",
        ")\n",
        "\n",
        "# Define the paths\n",
        "input_file_path = '/mnt/data/0A534BFB-8002-418E-B3AA-661E5EB369AC.wav'\n",
        "resampled_file_path = '/mnt/data/resampled_0A534BFB-8002-418E-B3AA-661E5EB369AC.wav'\n",
        "output_file_path = '/mnt/data/enhanced_dns4-16k_0A534BFB-8002-418E-B3AA-661E5EB369AC.wav'\n",
        "\n",
        "# Load and resample the audio file to 16000 Hz\n",
        "audio, _ = librosa.load(input_file_path, sr=16000)\n",
        "sf.write(resampled_file_path, audio, 16000)\n",
        "\n",
        "# Apply the model\n",
        "est_sources = model.separate_file(path=resampled_file_path)\n",
        "\n",
        "# Save the separated source to a new file\n",
        "torchaudio.save(output_file_path, est_sources[:, :, 0].detach().cpu(), 16000)\n",
        "\n",
        "# Provide the path to the processed file\n",
        "output_file_path"
      ],
      "metadata": {
        "id": "OWM4ZQYidIvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# working----\n",
        "import torchaudio\n",
        "from speechbrain.pretrained import WaveformEnhancement\n",
        "\n",
        "enhance_model = WaveformEnhancement.from_hparams(\n",
        "    source=\"speechbrain/mtl-mimic-voicebank\",\n",
        "    savedir=\"pretrained_models/mtl-mimic-voicebank\",\n",
        ")\n",
        "enhanced = enhance_model.enhance_file(\"/content/0A534BFB-8002-418E-B3AA-661E5EB369AC.wav\")\n",
        "\n",
        "# Saving enhanced signal on disk\n",
        "torchaudio.save('/content/0A534BFB-8002-418E-B3AA-661E5EB369AC_enhanced.wav', enhanced.unsqueeze(0).cpu(), 16000)"
      ],
      "metadata": {
        "id": "q4CupAGudkyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# working----\n",
        "import torch\n",
        "from speechbrain.pretrained import SpectralMaskEnhancement\n",
        "\n",
        "# Initialize the SpectralMaskEnhancement model\n",
        "enhancer = SpectralMaskEnhancement.from_hparams(\n",
        "    source=\"speechbrain/metricgan-plus-voicebank\"\n",
        ")\n",
        "\n",
        "# Enhance an audio file\n",
        "enhanced = enhancer.enhance_file(\n",
        "    \"/content/test_audio.wav\"\n",
        ")\n",
        "# Saving enhanced signal on disk\n",
        "torchaudio.save('/content/test_audio_enhanced_audio.wav', enhanced.unsqueeze(0).cpu(), 16000)"
      ],
      "metadata": {
        "id": "xPiBqv4Idq6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install noisereduce\n",
        "\n",
        "import noisereduce as nr\n",
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "\n",
        "\n",
        "# Load the audio file\n",
        "file_path = '/content/0A534BFB-8002-418E-B3AA-661E5EB369AC.wav'  # Replace with the path to your audio file\n",
        "audio, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "# Perform noise reduction\n",
        "denoised_audio = nr.reduce_noise(sr=sr, y=audio)\n",
        "\n",
        "\n",
        "# Normalize the denoised audio to the same RMS level as the original audio\n",
        "rms_original = np.sqrt(np.mean(audio**2))\n",
        "rms_denoised = np.sqrt(np.mean(denoised_audio**2))\n",
        "normalized_audio = denoised_audio * (rms_original / rms_denoised)\n",
        "\n",
        "# Save the normalized denoised audio to a new file\n",
        "output_file_path = '/content/file1.wav'  # Replace with the path where you want to save the output file\n",
        "sf.write(output_file_path, normalized_audio, sr)"
      ],
      "metadata": {
        "id": "7EmTLTa4dxfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Conservative spectral Gatting\n",
        "\n",
        "# Re-importing necessary libraries and redefining the functions\n",
        "import librosa\n",
        "import numpy as np\n",
        "from scipy.signal import stft, istft\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "\n",
        "# Redefining the noise reduction and normalization functions\n",
        "def conservative_spectral_gating_noise_reduction(signal, noise_segment, n_fft=2048, hop_length=512, alpha=0.3):\n",
        "    _, _, Zxx = stft(signal, nperseg=n_fft, noverlap=hop_length)\n",
        "    _, _, Zxx_noise = stft(noise_segment, nperseg=n_fft, noverlap=hop_length)\n",
        "    noise_mean = np.mean(np.abs(Zxx_noise), axis=1)\n",
        "    gain = np.maximum(1 - alpha * (noise_mean[:, np.newaxis] / (np.abs(Zxx) + 1e-10)), 0)\n",
        "    Zxx_reduced = gain * Zxx\n",
        "    _, reduced_signal = istft(Zxx_reduced, noverlap=hop_length)\n",
        "    reduced_signal *= np.linalg.norm(signal) / np.linalg.norm(reduced_signal)\n",
        "    return reduced_signal\n",
        "\n",
        "\n",
        "def normalize_audio(input_signal, target_rms=0.1):\n",
        "    current_rms = np.sqrt(np.mean(np.square(input_signal)))\n",
        "    if current_rms == 0:\n",
        "        return input_signal\n",
        "    factor = target_rms / current_rms\n",
        "    normalized_audio = input_signal * factor\n",
        "    return normalized_audio\n",
        "\n",
        "\n",
        "# Load the uploaded file again\n",
        "file_path = '/content/0A534BFB-8002-418E-B3AA-661E5EB369AC.wav'\n",
        "signal, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "# Assume the first second of the audio is representative of the noise in the file.\n",
        "noise_segment = signal[:sr]  # First second for noise\n",
        "\n",
        "# Apply the conservative spectral gating noise reduction method again\n",
        "conservative_spectral_reduced_audio = conservative_spectral_gating_noise_reduction(signal, noise_segment)\n",
        "\n",
        "# Normalize the amplitude of the reduced audio again\n",
        "conservative_spectral_normalized_audio = normalize_audio(conservative_spectral_reduced_audio)\n",
        "\n",
        "# Save the processed audio to a new file again\n",
        "conservative_processed_file_path = '/content/conservative_processed_spectral_0A534BFB-8002-418E-B3AA-661E5EB369AC.wav'\n",
        "write(conservative_processed_file_path, sr, conservative_spectral_normalized_audio.astype(np.float32))\n",
        "\n",
        "# Provide the path to the processed file\n",
        "conservative_processed_file_path"
      ],
      "metadata": {
        "id": "smogPH3Rd57f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adaptive Noise Reduction\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "\n",
        "# Load the audio file\n",
        "audio_file_path = \"/content/drive/MyDrive/AI internship/Audio_files/1/0699CB4D-B694-4922-ABAD-3E50C67D6C19.wav\"\n",
        "y, sr = librosa.load(audio_file_path, sr=None)\n",
        "\n",
        "# ---- Adaptive Noise Reduction using Spectral Gating ----\n",
        "def spectral_gating(y, sr, noise_reduction_factor=1.5):\n",
        "    S_full, phase = librosa.magphase(librosa.stft(y))\n",
        "    S_filter = librosa.decompose.nn_filter(S_full,\n",
        "                                           aggregate=np.median,\n",
        "                                           metric='cosine',)\n",
        "    S_filter = np.minimum(S_full, S_filter)\n",
        "    margin_i, margin_v = 2, 10\n",
        "    power = 2\n",
        "\n",
        "    mask_i = librosa.util.softmask(S_filter,\n",
        "                                   margin_i * (S_full - S_filter),\n",
        "                                   power=power)\n",
        "\n",
        "    mask_v = librosa.util.softmask(S_full - S_filter,\n",
        "                                   margin_v * S_filter,\n",
        "                                   power=power)\n",
        "\n",
        "    S_foreground = mask_v * S_full\n",
        "    y_denoised = librosa.istft(S_foreground * phase)\n",
        "    return y_denoised\n",
        "\n",
        "y_denoised = spectral_gating(y, sr)\n",
        "\n",
        "# ---- Selective Amplification ----\n",
        "def selective_amplification(y, frame_length=1024, hop_length=512, gain_factor=1.2):\n",
        "    # Divide the audio into frames\n",
        "    frames = librosa.util.frame(y, frame_length=frame_length, hop_length=hop_length).T\n",
        "\n",
        "    # Initialize an empty array to store the amplified audio\n",
        "    amplified_audio = np.array([])\n",
        "\n",
        "    # Loop through each frame\n",
        "    for frame in frames:\n",
        "        # Calculate the amplitude of this frame\n",
        "        amplitude = np.mean(np.abs(frame))\n",
        "\n",
        "        # If the amplitude is below a certain threshold, amplify it\n",
        "        if amplitude < 0.05:  # Threshold can be adjusted\n",
        "            frame = frame * gain_factor\n",
        "\n",
        "        # Append the frame to the amplified_audio array\n",
        "        amplified_audio = np.concatenate([amplified_audio, frame])\n",
        "\n",
        "    return amplified_audio\n",
        "\n",
        "y_amplified = selective_amplification(y_denoised)\n",
        "\n",
        "# ---- Save the processed audio ----\n",
        "sf.write(\"adaptive_noise_reduced_audio.wav\", y_denoised, sr)\n",
        "sf.write(\"selective_amplified_audio.wav\", y_amplified, sr"
      ],
      "metadata": {
        "id": "yk-VB0KHeCKh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}